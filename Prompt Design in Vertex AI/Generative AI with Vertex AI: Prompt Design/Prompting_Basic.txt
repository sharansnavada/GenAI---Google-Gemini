Basics about Prompting

What is prompt design and prompt engineering
Prompt design is the process of creating prompts that elicit the desired response from language models. Writing well structured prompts can be an essential part of ensuring accurate, high quality responses from a language model. The iterative process of repeatedly updating prompts and assessing the model's responses is sometimes called prompt engineering.

Components of a prompt
You can include whatever information you want in a prompt that you think is important for the task at hand. Generally, prompt content fall within one of the following components:
* Task (required)
* System instructions (optional)
* Few-shot examples (optional)
* Contextual information (optional)

Task
A task is the text in the prompt that you want the model to provide a response for. Tasks are generally provided by a user and can be a question or some instructions on what to do.

System instructions
System instructions are instructions that get passed to the model before any user input in the prompt. You can add system instructions in the dedicated systemInstruction parameter.
In the following example, system instructions are used to dictate the style and tone of the model, while adding constraints to what it can and can't talk about:
￼
Few-shot examples
Few-shot examples are examples that you include in a prompt to show the model what getting it right looks like. Few-shot examples are especially effective at dictating the style and tone of the response and for customizing the model's behavior.

Contextual information
Contextual information, or context, is information that you include in the prompt that the model uses or references when generating a response. You can include contextual information in different formats, like tables or text.
Prompt:


| Marble color | Number of marbles |
| ------------ | ----------------- |
| Red          | 12                |
| Blue         | 28                |
| Yellow       | 15                |
| Green        | 17                |

How many green marbles are there?
Response:


There are 17 green marbles.

Safety and fallback responses
There are a few use cases where the model is not expected to fulfill the user's requests. Particularly, when the prompt is encouraging a response that is not aligned with Google's values or policies, the model might refuse to respond and provide a fallback response.
Here are a few cases where the model is likely to refuse to respond:
* Hate Speech: Prompts with negative or harmful content targeting identity and/or protected attributes.
* Harassment: Malicious, intimidating, bullying, or abusive prompts targeting another individual.
* Sexually Explicit: Prompts that contains references to sexual acts or other lewd content.
* Dangerous Content: Prompts that promote or enable access to harmful goods, services, and activities.
